# -*- coding: utf-8 -*-
"""Policy-Pilot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j8TD2Q5PGWSwC-BMkdcw3lTgvP0lCttv
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install langchain==0.1.16
# !pip install transformers==4.41.2
# !pip install huggingface-hub==0.23.4
# !pip install sentence-transformers==2.5.1
# !pip install chromadb
# !pip install --upgrade torch --index-url https://download.pytorch.org/whl/cpu
# !pip install langchain-huggingface

!pip install sentence-transformers

!pip install --upgrade --force-reinstall numpy==1.26.4 scipy==1.17.0 scikit-learn==1.6.1

!pip install langchain-huggingface

def warn(*args,**kwargs):
    pass
import warnings
warnings.warn = warn
warnings.filterwarnings('ignore')

from langchain_community.document_loaders import TextLoader

from langchain_text_splitters import RecursiveCharacterTextSplitter

from langchain_huggingface import HuggingFaceEmbeddings

from langchain_community.vectorstores import Chroma

from langchain_core.runnables import RunnablePassthrough

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

from langchain_huggingface import HuggingFacePipeline

filename="/content/companyPolicies.txt"
file=open(filename, mode='r')
text=file.read()
text

import re

pattern = r"\n?\s*(\d+\.\s+[^\n]+)\n+"
parts = re.split(pattern, text)

sections = []
for i in range(1, len(parts), 2):
    title = parts[i].strip()
    body = parts[i+1].strip()

    full_section = title + "\n" + body

    # VERY IMPORTANT: drop anything that is too small
    if len(full_section) > 300:
        sections.append(full_section)

len(sections)

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=100
)

docs = []
for sec in sections:
    docs.extend(splitter.create_documents([sec]))

len(docs)

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

docsearch = Chroma.from_documents(
    docs,
    embeddings,
    collection_name="company_policy_v2"
)

docs_with_scores = docsearch.similarity_search_with_score("what is the code of conduct", k=4)

docs_with_scores.sort(key=lambda x: x[1])

docs = [doc for doc, _ in docs_with_scores[:3]]

docs_with_scores

docs

QA_PROMPT = """
You must answer the question ONLY using the context below.

Rules:
- Every sentence must include a citation like [Doc X].
- Do NOT use outside knowledge.
- If the answer is not present, say:
"I don't know based on the provided documents."

Context:
{context}

Question:
{question}

Answer:
"""

import torch
model_id = "Qwen/Qwen2.5-7B-Instruct"

tokenizer = AutoTokenizer.from_pretrained(model_id)

model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    device_map="auto",
    resume_download=True,
    use_safetensors=True
)
pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=120,
    do_sample=True,
    temperature=0.7,
    return_full_text=False
)
llm = HuggingFacePipeline(pipeline=pipe)

llm.generate(
    ["Summarize supervised vs unsupervised learning in 5 bullet points"]
)

docs = docsearch.similarity_search_with_score("what is the recruitment policy?", k=2)
docs

def answer_question(question: str):
    docs_with_scores = docsearch.similarity_search_with_score(question, k=2)
    docs_with_scores.sort(key=lambda x: x[1])

    docs = [doc for doc, _ in docs_with_scores]

    context = "\n\n".join(
        f"[Doc{i+1}] {doc.page_content.strip()}"
        for i, doc in enumerate(docs)
    )

    answer = llm.invoke(QA_PROMPT.format(
        context=context,
        question=question
    ))

    return answer.strip()

import gradio as gr

with gr.Blocks(title="Company Policy QA Assistant") as demo:
    gr.Markdown(
        """
        ## Company Policy Question Answering
        Ask questions about company policies.
        Answers are generated **strictly from the documents**.
        """
    )

    with gr.Row():
        question_input = gr.Textbox(
            label="Ask a question",
            placeholder="e.g. What is the recruitment policy?",
            lines=2
        )

    answer_output = gr.Textbox(
        label="Answer",
        lines=6,
        interactive=False
    )

    submit_btn = gr.Button("Get Answer")

    submit_btn.click(
        fn=answer_question,
        inputs=question_input,
        outputs=answer_output
    )

demo.launch()

import pandas as pd

data = [
    {"policy": "Code of Conduct", "question": "What are the core principles outlined in the Code of Conduct?",
     "answer": "The core principles are integrity, respect, accountability, safety, and environmental responsibility."},

    {"policy": "Code of Conduct", "question": "What does integrity mean according to the Code of Conduct?",
     "answer": "Integrity means acting honestly and transparently, protecting sensitive information, and avoiding conflicts of interest."},

    {"policy": "Recruitment Policy", "question": "Does the organization follow an equal opportunity recruitment process?",
     "answer": "Yes, the organization is an equal opportunity employer and does not discriminate based on protected characteristics."},

    {"policy": "Internet and Email Policy", "question": "Is personal use of company internet and email allowed?",
     "answer": "Limited personal use is allowed during non-work hours as long as it does not interfere with work responsibilities."},

    {"policy": "Mobile Phone Policy", "question": "What should an employee do if a mobile device is lost or stolen?",
     "answer": "The employee must immediately report it to the IT department or their supervisor."},

    {"policy": "Smoking Policy", "question": "Where is smoking permitted on company premises?",
     "answer": "Smoking is only permitted in designated smoking areas marked by appropriate signage."},

    {"policy": "Drug and Alcohol Policy", "question": "Is alcohol consumption allowed during work hours?",
     "answer": "Alcohol consumption is not allowed during work hours or on company property, except for company-sanctioned events."},

    {"policy": "Health and Safety Policy", "question": "Who is responsible for maintaining workplace health and safety?",
     "answer": "Every individual within the organization is responsible for upholding health and safety standards."},

    {"policy": "Anti-Discrimination Policy", "question": "How should incidents of harassment be reported?",
     "answer": "Incidents should be reported to a supervisor, manager, or designated HR representative."},

    {"policy": "Discipline and Termination Policy", "question": "What disciplinary actions can the organization take?",
     "answer": "Actions may include verbal warnings, written warnings, suspension, or other appropriate measures."}
]

df = pd.DataFrame(data)
df

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
def cos_sim(a, b):
    return cosine_similarity(
        np.array(a).reshape(1, -1),
        np.array(b).reshape(1, -1)
    )[0][0]

from sentence_transformers import SentenceTransformer
THRESHOLD = 0.60
model = SentenceTransformer("all-MiniLM-L6-v2")
correct = 0

for i in range(len(df)):
    question = df.iloc[i]["question"]
    gt_answer = df.iloc[i]["answer"]

    docs_with_scores = docsearch.similarity_search(question, k=3)

    gt_emb = model.encode(gt_answer)

    best_sim = 0

    for doc in docs_with_scores:
        doc_emb = model.encode(doc.page_content)
        sim = cos_sim(gt_emb, doc_emb)
        best_sim = max(best_sim, sim)

    if best_sim >= THRESHOLD:
        correct += 1

accuracy = correct / len(df)
print(f"Accuracy: {accuracy:.2%}")

sims = []

for i in range(len(df)):
    question = df.iloc[i]["question"]
    gt_answer = df.iloc[i]["answer"]
    docs = docsearch.similarity_search(question, k=3)

    gt_emb = model.encode(gt_answer)

    for doc in docs:
        sim = cos_sim(gt_emb, model.encode(doc.page_content))
        sims.append(sim)

print(sims)

print(min(sims),max(sims))

c=[]
for t in [0.5, 0.55, 0.6, 0.65, 0.7]:
    correct = 0
    for i in range(len(df)):
        gt = df.iloc[i]["answer"]
        docs = docsearch.similarity_search(df.iloc[i]["question"], k=3)
        gt_emb = model.encode(gt)

        best = max(
            cos_sim(gt_emb, model.encode(doc.page_content))
            for doc in docs
        )

        if best >= t:
            correct += 1
    c.append(correct)
    print(f"Threshold {t}: {correct/len(df):.2%}")

import matplotlib.pyplot as plt
import numpy as np
c_arr = np.array(c)
t_values = np.array([0.5, 0.55, 0.6, 0.65, 0.7])
plt.plot(c_arr, t_values)
plt.xlabel("Correct Answers Count")
plt.ylabel("Threshold")
plt.title("Accuracy vs Threshold")
plt.grid(True)
plt.show()